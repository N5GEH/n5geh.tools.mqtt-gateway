"""
This module contains utility functions that are used by the load-tests.
Depending on the TEST_ENV environment variable, the load-tests will be run in baseline or gateway mode.
"""

import asyncio
import json
import os
import time
from random import randint
from typing import Union, Tuple
import pickle

import aiohttp
from asyncio_mqtt import Client as MQTTClient

TEST_ENV = os.environ.get("TEST_ENV", "gateway1x")
HOST_URL = "137.226.248.161"


async def generate_random_string(length: int = 10) -> str:
    """
    Generate a random string of the specified length. This is used to generate random entity_id, entity_type, device_id and attribute_name
    that are not already in use by the Orion Context Broker as we need to see whether the matching works properly.
    This is a very naive implementation, but it is sufficient for our purposes and makes use of the ascii table.
    Digits can be generated by using the range 48-57, uppercase letters by using the range 65-90 and lowercase letters by using the range 97-122.
    At the end of the day, we just need to generate an 'attribute name' that is not registered in the Context Broker entity.
    """
    return "".join([chr(randint(97, 122)) for _ in range(length)])


async def generate_entity() -> Union[Tuple[str, str, str, str]]:
    """
    Generate a random entity with a random attribute. This is used to test whether the matching works properly
    as well as to create an entity that is not already registered in the Context Broker.

    Returns:
        Union[str, str, str, str]: device_id, entity_id, entity_type, attribute_name (but frankly they are all just random strings)
    """
    # Generate a random device_id, entity_id, entity_type and attribute_name
    return (
        await generate_random_string(),
        await generate_random_string(),
        await generate_random_string(),
        await generate_random_string(),
    )


async def generate_payload(attribute_name: str = "") -> str:
    """
    Generate a payload with a random attribute and a timestamp. A fake attribute is also generated to test whether the matching works properly.

    Args:
        attribute_name (str, optional): The name of the attribute. Defaults to "".
        baseline (bool, optional): Whether the function is used for baseline benchmarking. Defaults to False.

    Returns:
        str: The payload as a JSON string.
    """
    fake_attribute = await generate_random_string(10)
    return json.dumps({fake_attribute: randint(0, 1000), attribute_name: time.time()})


async def generate_fiware_header():
    """
    Generate the FIWARE headers for the requests. This is used to test whether the matching works properly.
    """
    if TEST_ENV not in ["baseline", "gateway1x", "gateway4x"]:
        raise ValueError("TEST_ENV must be either 'baseline' or 'gateway'")
    # return {
    #     "fiware-service": "baseline" if TEST_ENV == "baseline" else "gateway",
    #     "fiware-servicepath": "/baseline" if TEST_ENV == "baseline" else "/gateway",
    # }
    return {
        "fiware-service": "gateway_test",
        "fiware-servicepath": "/",
    }


async def register_entity(
        session: aiohttp.ClientSession,
        entity_id: str,
        entity_type: str,
        attribute_name: str,
):
    return await session.post(
        f"http://{HOST_URL}:1026/v2/entities",
        json={
            "id": entity_id,
            "type": entity_type,
            attribute_name: {"value": 0, "type": "Number"},
        },
        headers={
            "fiware-service": "baseline" if TEST_ENV == "baseline" else "gateway",
            "fiware-servicepath": "/baseline" if TEST_ENV == "baseline" else "/gateway",
        },
    )


async def register_device(
        session: aiohttp.ClientSession,
        device_id: str,
        entity_id: str,
        entity_type: str,
        attribute_name: str,
):
    return await session.post(
        f"http://{HOST_URL}:4041/iot/devices",
        json={
            "devices": [
                {
                    "device_id": device_id,
                    "entity_name": entity_id,
                    "entity_type": entity_type,
                    "timezone": "Europe/Berlin",
                    "transport": "MQTT",
                    "attributes": [
                        {
                            "object_id": attribute_name,
                            "name": attribute_name,
                            "type": "Number",
                        }
                    ]
                }
            ]
        },
        headers=await generate_fiware_header(),
    )


async def generate_subscription(
        session: aiohttp.ClientSession,
        entity_id: str,
        entity_type: str,
        attribute_name: str,
):
    listener_id = randint(0, 3)
    return await session.post(
        f"http://{HOST_URL}:1026/v2/subscriptions",
        json={
            "description": f"Baseline test subscription for {entity_id}:{attribute_name}",
            "subject": {
                "entities": [{"id": entity_id, "type": entity_type}],
                "condition": {"attrs": [attribute_name]},
            },
            "notification": {
                "mqtt": {
                    "url": f"mqtt://{HOST_URL}:1883",
                    "qos": 0,
                    "topic": f"test/timestamp/{listener_id}",
                },
                "attrs": [attribute_name],
                "metadata": ["dateCreated", "dateModified"],
            },
            "expires": "2040-01-01T14:00:00.00Z",
        },
        headers=await generate_fiware_header(),
    )


async def generate_client(
        event: asyncio.Event, mqtt_hostname: str = "localhost", mqtt_port: int = 1883
):
    """
    Generate a client and publish a payload to the test/latency topic every second.
    The client continuously publishes a payload every second until it is cancelled. Each payload consists of
    a real and a fake attribute and a timestamp. The real attribute is used to test whether the matching works
    properly, while the timestamp is used to calculate the latency.
    """
    try:
        async with MQTTClient(mqtt_hostname) as client:
            await event.wait()
            await client.connect()
            while True:
                if TEST_ENV == "baseline":
                    await client.publish("test/latency", await generate_payload())
                elif TEST_ENV == "gateway":
                    await client.publish(
                        "test/latency",
                        await generate_payload(attribute_name="timestamp"),
                    )
                await asyncio.sleep(1)
    except Exception as e:
        print(f"An error occurred: {e}")


def save_results_after_stage(messages_sent: list, messages_received: list, latencies: list, stage: int) -> None:
    """
    Save the results after each stage of the benchmarking process using pickle. This is used to calculate the latency and throughput.
    """
    with open(f"tests/results/pickles/results_{TEST_ENV}_{stage}.pkl", "wb") as f:
        pickle.dump(
            {
                "messages_sent": messages_sent,
                "messages_received": messages_received,
                "latencies": latencies,
                "stage": stage,
            },
            f,
        )
